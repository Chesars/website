{
  "name": "pydantic ai",
  "slug": "pydantic__pydantic-ai__mcp-run-python",
  "description": "Agent Framework / shim to use Pydantic with LLMs",
  "readme": "# MCP Run Python\n\n[Model Context Protocol](https://modelcontextprotocol.io/) server to run Python code in a sandbox.\n\nThe code is executed using [Pyodide](https://pyodide.org) in [Deno](https://deno.com/) and is therefore isolated from\nthe rest of the operating system.\n\n**See <https://ai.pydantic.dev/mcp/run-python/> for complete documentation.**\n\nThe server can be run with `deno` installed using:\n\n```bash\ndeno run \\\n  -N -R=node_modules -W=node_modules --node-modules-dir=auto \\\n  jsr:@pydantic/mcp-run-python [stdio|sse|warmup]\n```\n\nwhere:\n\n- `-N -R=node_modules -W=node_modules` (alias of `--allow-net --allow-read=node_modules --allow-write=node_modules`)\n  allows network access and read+write access to `./node_modules`. These are required so pyodide can download and cache\n  the Python standard library and packages\n- `--node-modules-dir=auto` tells deno to use a local `node_modules` directory\n- `stdio` runs the server with the\n  [Stdio MCP transport](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/transports/#stdio) —\n  suitable for running the process as a subprocess locally\n- `sse` runs the server with the\n  [SSE MCP transport](https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/transports/#http-with-sse) —\n  running the server as an HTTP server to connect locally or remotely\n- `warmup` will run a minimal Python script to download and cache the Python standard library. This is also useful to\n  check the server is running correctly.\n\nHere's an example of using `@pydantic/mcp-run-python` with Pydantic AI:\n\n```python\nfrom pydantic_ai import Agent\nfrom pydantic_ai.mcp import MCPServerStdio\n\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_mcp()\nlogfire.instrument_pydantic_ai()\n\nserver = MCPServerStdio('deno',\n    args=[\n        'run',\n        '-N',\n        '-R=node_modules',\n        '-W=node_modules',\n        '--node-modules-dir=auto',\n        'jsr:@pydantic/mcp-run-python',\n        'stdio',\n    ])\nagent = Agent('claude-3-5-haiku-latest', toolsets=[server])\n\n\nasync def main():\n    async with agent:\n        result = await agent.run('How many days between 2000-01-01 and 2025-03-18?')\n    print(result.output)\n    #> There are 9,208 days between January 1, 2000, and March 18, 2025.w\n\nif __name__ == '__main__':\n    import asyncio\n    asyncio.run(main())\n```\n",
  "category": null,
  "qualityScore": 94,
  "githubUrl": "https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python",
  "programmingLanguage": "Python",
  "gitHubOrg": "pydantic",
  "gitHubRepo": "pydantic-ai",
  "repositoryPath": "mcp-run-python",
  "gh_stars": 11366,
  "gh_contributors": 30,
  "gh_issues": 0,
  "gh_releases": true,
  "gh_ci_cd": true,
  "gh_latest_commit_hash": "80a7284f24a780930381920bfcf8a1ce68463860",
  "last_scraped_at": "2025-08-01T13:16:30.221Z",
  "implementing_tools": null,
  "implementing_prompts": null,
  "implementing_resources": null,
  "implementing_sampling": null,
  "implementing_roots": null,
  "implementing_logging": null,
  "implementing_stdio": null,
  "implementing_streamable_http": null,
  "implementing_oauth2": null
}